#!/usr/bin/env python3
"""
Test script to validate JSON recording functionality and search result quality
"""

import json
import sys
import os
from pathlib import Path

# Add the project root to Python path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from utils.json_recorder import JSONRecorder

def test_json_recording_system():
    """Test the JSON recording system functionality"""
    print("ğŸ§ª Testing JSON Recording System")
    print("=" * 50)

    try:
        # Initialize JSON recorder
        json_recorder = JSONRecorder()
        print(f"âœ… JSONRecorder initialized: {json_recorder.base_directory}")

        # List saved searches
        saved_searches = json_recorder.list_saved_searches()
        print(f"âœ… Found {len(saved_searches)} saved search files")

        if saved_searches:
            # Analyze the most recent search
            latest_search = saved_searches[0]
            print(f"ğŸ“ Latest search file: {Path(latest_search).name}")

            # Get search summary
            summary = json_recorder.get_search_summary(latest_search)
            print(f"ğŸ” Search Summary:")
            print(f"   â€¢ Search Term: {summary.get('search_term', 'N/A')}")
            print(f"   â€¢ Timestamp: {summary.get('timestamp', 'N/A')}")
            print(f"   â€¢ Total Results: {summary.get('total_results', 0)}")
            print(f"   â€¢ Dimensions with Results: {summary.get('dimensions_with_results', 0)}")
            print(f"   â€¢ Search Coverage: {summary.get('search_coverage', 0)}")

            # Load and analyze full data
            full_data = json_recorder.load_search_results(latest_search)

            print(f"\nğŸ“Š Search Result Quality Analysis:")
            print(f"   â€¢ Search Coverage: {full_data['search_metadata']['search_coverage']}/8 dimensions")

            stats = full_data.get('statistics', {})
            dimension_breakdown = stats.get('dimension_breakdown', {})

            print(f"   â€¢ Total Results: {stats.get('total_results', 0)}")
            print(f"   â€¢ Dimensions Breakdown:")

            for dimension, count in dimension_breakdown.items():
                if count > 0:
                    print(f"     - {dimension.replace('_', ' ').title()}: {count} results âœ…")
                else:
                    print(f"     - {dimension.replace('_', ' ').title()}: {count} results âŒ")

            # Analyze search result quality
            analyze_search_quality(full_data)

        else:
            print("âš ï¸ No saved searches found yet")

    except Exception as e:
        print(f"âŒ Error testing JSON recording system: {str(e)}")
        return False

    return True

def analyze_search_quality(data):
    """Analyze the quality of search results"""
    print(f"\nğŸ¯ Search Quality Analysis:")

    search_results = data.get('search_results', {})

    # Check direct matches quality
    direct_matches = search_results.get('direct_matches', [])
    if direct_matches:
        sample_match = direct_matches[0]
        print(f"   â€¢ Direct Matches: {len(direct_matches)} found")
        print(f"     - Sample problem: {sample_match.get('p', {}).get('name', 'N/A')[:60]}...")
        print(f"     - Root cause provided: {'âœ…' if sample_match.get('rc', {}).get('root_cause') else 'âŒ'}")
        print(f"     - Action plan available: {'âœ…' if sample_match.get('ap', {}) else 'âŒ'}")

    # Check equipment patterns
    equipment_patterns = search_results.get('equipment_patterns', [])
    if equipment_patterns:
        print(f"   â€¢ Equipment Patterns: {len(equipment_patterns)} found")
        print(f"     - Pattern analysis working: âœ…")

    # Check causal chains
    causal_chains = search_results.get('causal_chains', [])
    if causal_chains:
        print(f"   â€¢ Causal Chains: {len(causal_chains)} found")
        print(f"     - Relationship mapping working: âœ…")

    # Check cross-facility patterns
    cross_facility = search_results.get('cross_facility_patterns', [])
    if cross_facility:
        print(f"   â€¢ Cross-Facility Patterns: {len(cross_facility)} found")
        print(f"     - Knowledge sharing opportunities: âœ…")

    # Overall quality assessment
    stats = data.get('statistics', {})
    total_results = stats.get('total_results', 0)
    dimensions_with_results = stats.get('dimensions_with_results', 0)

    if total_results > 50 and dimensions_with_results >= 3:
        quality_rating = "ğŸŸ¢ Excellent"
    elif total_results > 20 and dimensions_with_results >= 2:
        quality_rating = "ğŸŸ¡ Good"
    elif total_results > 0:
        quality_rating = "ğŸŸ  Fair"
    else:
        quality_rating = "ğŸ”´ Poor"

    print(f"\nğŸ† Overall Search Quality: {quality_rating}")
    print(f"   â€¢ Search Term: '{data['search_metadata']['search_term']}'")
    print(f"   â€¢ Multi-dimensional coverage: {dimensions_with_results}/8 dimensions")
    print(f"   â€¢ Result richness: {total_results} total results")

if __name__ == "__main__":
    print("ğŸš€ JSON Recording System Validation")
    print("=" * 60)

    success = test_json_recording_system()

    if success:
        print(f"\nâœ… JSON Recording System is working perfectly!")
        print(f"ğŸ“ Search results are being saved to: data/search_results/")
        print(f"ğŸ’¾ JSON files contain comprehensive search metadata and statistics")
    else:
        print(f"\nâŒ Issues detected in JSON recording system")

    print("=" * 60)
